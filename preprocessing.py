# -*- coding: utf-8 -*-
"""preprocessing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cdLifHPMXMy2UHDJMRY0WDPE40-iDBDJ
"""

!pip install konlpy

"""#one week"""

# -*- coding: utf-8 -*-
"""
@author: yijin
"""

import os
import pandas as pd
import re
from konlpy.tag import Okt
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
import pickle
import warnings
warnings.filterwarnings("ignore") # ignore warning messages

def set_root_dir(location):
    if location == 'colab':
      root_dir = '/content/drive/MyDrive/journal'
      os.chdir(root_dir)
    else: ##location == 'local'
      root_dir = os.getcwd()
    data_dir = os.path.join(root_dir, "data")
    
    print('YOUR WORKING DIR: ', root_dir)
    print('YOUR DATA DIR: ', data_dir)
    return root_dir, data_dir
          
def read_csv(filename):
    return pd.read_csv(os.path.join(data_dir, filename), encoding='utf-8')

def save_csv(df, filename):
    return df.to_csv(os.path.join(data_dir, filename), index=False)


class StepOne:     
    def __init__(self, filename, column_list):
        self.data = read_csv(filename)
        self.column_list = column_list
#         print('shape:', self.data.shape)          
    def stepone(self):
        self.extract_weeks()
        self.organize_rows_cols()
        print('=====Step One Completed=====')
        return self.data

    def extract_weeks(self):
        temp1 = self.data['create_date'].str[0:10]>= '2019-12-03'
        temp2 =  self.data['create_date'].str[0:10] <= '2019-12-09'
        self.data =  self.data[temp1 &temp2]
        print('Data is for {} days and shape is {}'.format(len(pd.unique( self.data['create_date'].str[0:10])), self.data.shape))  #Check if the data is for 7 days
#         save_csv( self.data, 'extract_weeks.csv')

    def organize_rows_cols(self):
        self.data = self.data[column_list]
        self.data = self.data.dropna(axis=0)
        self.data= self.data.drop_duplicates()
        self.split_category()
        self.del_unnecessary_cate()                          
          
    def split_category(self):
        self.data['category_id'] = self.data['category_id'].map(lambda x:int(x))
        self.data['cate_one']   = self.data['category_id'].map(lambda x: str(x)[0:3])
        self.data['cate_two']   = self.data['category_id'].map(lambda x: str(x)[0:6])
        self.data = self.data.drop(['category_id'], axis=1)
          
    def del_unnecessary_cate(self):
        unnecessary_cate = [100, 200, 210, 220, 230, 240, 300, 999]
        for cate in unnecessary_cate:
            temp = self.data[self.data.cate_one.astype(int) == cate]
            self.data = self.data.drop(temp.index)
               
        temp = self.data[self.data.cate_two.astype(int)<1000]
        self.data = self.data.drop(temp.index)
        
class StepTwo:
    def __init__(self, dataframe, column_list):
        self.data = dataframe
        self.column_list = column_list
#         print('shape:', self.data.shape)        
    def steptwo(self):
        for colname in self.column_list:
            self.data[colname] = self.data[colname].apply(self.remove_new_line_character)
            self.data[colname] = self.data[colname].apply(self.re_sub_part)
            self.data[colname] = self.data[colname].apply(self.remove_spaces)               
        print('=====Step Two Completed=====')
        return self.data

    def cleaning(self, str):
        self.remove_new_line_character()
        self.re_sub_part()
        self.remove_spaces()
    def remove_new_line_character(self, str):
        return re.sub(r'\\n', ' ', str)
    def re_sub_part(self, str):
        return re.sub('[^0-9a-zA-Z가-힗]', ' ', str)
    def remove_spaces(self, str):
        return re.sub(' +', ' ', str)
    
          
class StepThree:
    def __init__(self, dataframe, column_list):
        self.data = dataframe
        self.column_list = column_list
#         print('shape:', self.data.shape)          
    def stepthree(self):
        for colname in self.column_list:
            self.data[colname] = self.data[colname].map(self.okt_token)
        print('=====Step Three Completed=====')
        return self.data  
    def okt_token(self, text):
        okt = Okt()
        s = ''
        pos = okt.pos(text, norm = True, stem = True)
        for keyword, type in pos:
            if type == 'Noun' or type == 'Alpha' or type == 'Number':
                s = s + ' ' + keyword
        return s
    
class StepFour:
    def __init__(self, dataframe, column_list, stop_file):
        self.data = dataframe
        self.column_list = column_list
        self.stop_file = stop_file
    def stepfour(self):
        for colname in self.column_list:
            self.data[colname] = self.data[colname].map(self.remove_stopword)
        print('=====Step Four Completed=====')
        return self.data
        
    def remove_stopword(self, word):
        with open(os.path.join(data_dir, self.stop_file), 'r', encoding='utf-8') as f:
            stopword_str = f.read() 
        stop_word = stopword_str.split(' ')
        s = ''
        word_tokens = word_tokenize(str(word))
        for token in word_tokens:
            if token not in stop_word:
                s = s + token + ' '
        return s

class StepFive:
    def __init__(self, dataframe): 
        self.data = dataframe
        self.le = LabelEncoder()
    def stepfive(self):
        self.fit_label()
        self.print_label()
        self.save_label()
        print('=====Step Five Completed=====')
        return self.data

    def fit_label(self):
        self.le.fit(self.data['cate_two'].astype(str))
        self.data['label'] = self.le.fit_transform(self.data['cate_two'].astype(str))
#         print(self.data.head(2))        
    def print_label(self):
        with open(os.path.join(data_dir, 'label_mapping.txt'), 'w',encoding='utf-8') as f:
            for i, item in enumerate(self.le.classes_):
                f.write('{} --> {}\n'.format(item, i))
            f.write('Total Labels : {}'.format(len(self.le.classes_)))
#         print('Total Labels : ', len(self.le.classes_))
    def save_label(self):
        with open(os.path.join(data_dir, 'label_encoder.pkl'), 'wb')as f:
            pickle.dump(self.le, f)
            f.close()
        print('Save label encoder as pkl')
             
class ExploreData:
    def __init__(self,filename, column_list):
        self.data = read_csv(filename)
        self.column_list = column_list

    def explore_data(self):
        print('length of string')
        for colname in self.column_list:
            print('Column: ', colname)
            self.string_length(colname)

        print('================')
        for colname in self.column_list:
            print('word count: ', colname)
            self.count_words(colname)

        print('================')
        for colname in self.column_list:
            print('word frequency: ', colname)
            self.most_common_words(colname)


    def string_length(self,colname):
        self.data[colname+'_strlen'] = self.data[colname].str.len()
        print('└Max: ', max(self.data[colname +'_strlen']))
        print('└average: ', self.data[colname +'_strlen'].mean())
         
    def count_words(self,colname):
        self.data[colname +'_wordlen'] = self.data[colname].str.split().str.len()
        print('└Max: ', max(self.data[colname +'_wordlen']))
        print('└average: ', self.data[colname +'_wordlen'].mean())

    def most_common_words(self, colname):
        with open(data_dir + '{}_word_freq.txt'.format(colname), 'w', encoding='utf-8')as f:
            temp = self.data[colname].values
            temp = ' '.join(' '.join(temp.astype(str)).split())
            temp = temp.split(' ')
            globals()['c_{}'.format(colname)] = Counter(temp)
            count = 0
            for word, freq in globals()['c_{}'.format(colname)].most_common():
                if freq >= 10:
                    f.write("{} {}\n".format(word, freq))
                    count = count + 1
                    if count == 1000:
                        f.write('======================')
                else: #freq under 10
                    break      
            f.write('Number of most common in {} : {} {}'.format(colname, count, len(globals()['c_{}'.format(colname)])))    
        print('Number of most common in {} : {} {}'.format(colname, count, len(globals()['c_{}'.format(colname)])))

if __name__ == "__main__":
     # where you are working 'colab' or 'local'
    root_dir, data_dir = set_root_dir('colab')

    column_list = ['name', 'keyword', 'category_id', 'description']
    column_str_list = ['name', 'keyword', 'description']

    # step1 = StepOne('bunjang_product.csv', column_list)
    # data1 = step1.stepone()
    # save_csv(data1, 'result/1_selection_1week.csv')
    # print(data1.shape)
    # print(data1.dtypes)
    # step2 = StepTwo(data, column_str_list)
    # data = step2.steptwo()
    # save_csv(data, 'step2.csv')

    # step3 = StepThree(data, column_str_list)
    # data = step3.stepthree()
    # save_csv(data, 'step3.csv')

    # step4 = StepFour(data, column_str_list, file)
    # data = step4.stepfour()
    # save_csv(data, 'step4.csv')

    # step5 = StepFive(data)
    # data = step5.stepfive()
    # save_csv(data, 'step5.csv')

    # # exploredata = ExploreData('step5.csv', column_str_list)
    # # exploredata.explore_data()
